{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "from nltk.tokenize import  word_tokenize\n",
    "import tensorflow as tf\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import word embeddings and reformat\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = gensim.models.Word2Vec.load('nearby_embeddings2')\n",
    "wordVectors = []\n",
    "for word in word_vectors.wv.index2word:\n",
    "    wordVectors.append(word_vectors.wv[word])\n",
    "wordVectors = np.array(wordVectors)\n",
    "wordsList = word_vectors.wv.index2word\n",
    "\n",
    "max_sequence_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21682"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('/home/pratik/NER/data/large_positive.csv')\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16623"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.drop_duplicates(subset=['body'], inplace=True)\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_list(original_text_list):\n",
    "    l = ast.literal_eval(original_text_list)\n",
    "    l = [i.strip() for i in l]\n",
    "    return l\n",
    "raw_data['original_text'] = raw_data['original_text'].apply(lambda x: convert_to_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_y(text, original_text_list, k):\n",
    "    y = np.zeros([max_sequence_length, 2])\n",
    "    for i in range(len(y)):\n",
    "        y[i][0] = 1\n",
    "    for original_text_words in original_text_list:\n",
    "        for original_text in word_tokenize(original_text_words):\n",
    "            words = word_tokenize(text)\n",
    "            for i in range(len(words)):\n",
    "                if words[i].lower() == original_text.lower():\n",
    "                  #  print(words[i], original_text)\n",
    "                    y[i][1] = 1\n",
    "                    y[i][0] = 0\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_y(text, original_text_list, k):\n",
    "    y = np.zeros([max_sequence_length, 2])\n",
    "    try:\n",
    "        for i in range(len(y)):\n",
    "            y[i][0] = 1\n",
    "        for original_text_words in original_text_list:\n",
    "            for original_text in word_tokenize(original_text_words):\n",
    "                words = word_tokenize(text)\n",
    "                for i in range(len(words)):\n",
    "                    if words[i].lower() == original_text.lower():\n",
    "                      #  print(words[i], original_text)\n",
    "                        y[i][1] = 1\n",
    "                        y[i][0] = 0\n",
    "    except:\n",
    "        pass\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_list = np.zeros([len(raw_data), max_sequence_length, 2])\n",
    "for body, original_text_list, i in zip(raw_data['body'], raw_data['original_text'], range(len(raw_data))):\n",
    "    \n",
    "    y_list[i] = generate_y(body, original_text_list, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['No', 'I', 'ask', 'Paytm', 'debit', 'card', 'queries'],\n",
       " ['paytm debit'],\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(raw_data['body'].iloc[11]), raw_data['original_text'].iloc[11], y_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('nearby_ids2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "5        None\n",
       "6        None\n",
       "7        None\n",
       "8        None\n",
       "9        None\n",
       "10       None\n",
       "11       None\n",
       "12       None\n",
       "13       None\n",
       "14       None\n",
       "15       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "24       None\n",
       "25       None\n",
       "26       None\n",
       "27       None\n",
       "28       None\n",
       "29       None\n",
       "30       None\n",
       "         ... \n",
       "21287    None\n",
       "21288    None\n",
       "21289    None\n",
       "21290    None\n",
       "21291    None\n",
       "21292    None\n",
       "21293    None\n",
       "21294    None\n",
       "21295    None\n",
       "21296    None\n",
       "21297    None\n",
       "21298    None\n",
       "21299    None\n",
       "21301    None\n",
       "21302    None\n",
       "21304    None\n",
       "21305    None\n",
       "21306    None\n",
       "21307    None\n",
       "21309    None\n",
       "21310    None\n",
       "21311    None\n",
       "21312    None\n",
       "21313    None\n",
       "21316    None\n",
       "21318    None\n",
       "21319    None\n",
       "21320    None\n",
       "21321    None\n",
       "21322    None\n",
       "Name: body, Length: 16623, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vocab = []\n",
    "def get_character_set(text):\n",
    "    for char in text:\n",
    "        if not char in char_vocab:\n",
    "            char_vocab.append(char)\n",
    "\n",
    "raw_data['body'].apply(lambda x: get_character_set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_vocab_len = len(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_one_hot = np.zeros([char_vocab_len, char_vocab_len])\n",
    "for i in range(len(char_vocab)):\n",
    "    char_one_hot[i][i] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_char_length = 16\n",
    "max_sequence_length = 20\n",
    "char_dimensions = char_vocab_len\n",
    "batch_size = 100\n",
    "raw_data_len = len(raw_data)\n",
    "ids_char = np.zeros([(raw_data_len),max_sequence_length,max_char_length ])\n",
    "ids_char = ids_char + len(char_vocab) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = 0\n",
    "for i in (range((raw_data_len))):\n",
    "    body = raw_data.iloc[i]['body']\n",
    "    words = word_tokenize(body)\n",
    "    for j in (range(len(words))):\n",
    "        word = words[j]\n",
    "        for k in range(len(word)):\n",
    "            char = word[k]\n",
    "            try:\n",
    "                ids_char[i][j][k] = char_vocab.index(char)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16623, 20, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdiugfh Tensor(\"map/while/TensorArrayReadV3:0\", shape=(20, 16), dtype=float32)\n",
      "char_data Tensor(\"map/while/embedding_lookup:0\", shape=(20, 16, 158), dtype=int32)\n",
      "aya\n",
      "aya\n",
      "(20, 40)\n",
      "Tensor(\"map/while/Relu:0\", shape=(20, 40), dtype=float32)\n",
      "og (20, 40)\n",
      "con2 (20, 5, 2, 32)\n"
     ]
    }
   ],
   "source": [
    "#weights = {'W_conv1': tf.get_variable(\"W_conv1\", shape=([5,5,1,32]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'W_conv2':                tf.get_variable(\"W_conv2\", shape=([5,5,32,64]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'W_fc':tf.get_variable(\"W_fc\", shape=([(int(max_char_length//4))*(int(char_dimensions//4))*64,1024]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer())\n",
    "#           }\n",
    "\n",
    "\n",
    "\n",
    "#biases = {'b_conv1':tf.get_variable(\"b_conv1\", shape=([32]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'b_conv2':tf.get_variable(\"b_conv2\", shape=([64]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'b_fc':tf.get_variable(\"b_fc\", shape=([1024]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer())\n",
    "#           }\n",
    "weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "           'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "           'W_fc':tf.Variable(tf.random_normal([(int(10//2))*(int(4//2))*32,100])),\n",
    "           'out':tf.Variable(tf.random_normal([100, 10]))}\n",
    "\n",
    "biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "           'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "           'b_fc':tf.Variable(tf.random_normal([100])),\n",
    "           'out':tf.Variable(tf.random_normal([10]))}\n",
    "n_nodes_hl1 = 40\n",
    "hidden_1_layer = {'weights':tf.Variable(tf.random_normal([max_char_length * char_dimensions, n_nodes_hl1])),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "\n",
    "def character_level_embedding(char_input_data):\n",
    "    print('sdiugfh', char_input_data)\n",
    "    char_input_data = tf.cast(char_input_data, dtype=tf.int32)\n",
    "    char_one_hot_tensor = tf.convert_to_tensor(char_one_hot, dtype=tf.int32)\n",
    "    char_data = tf.placeholder(shape = (max_sequence_length,max_char_length), dtype=tf.int32)\n",
    "    char_data = tf.nn.embedding_lookup(char_one_hot_tensor,char_input_data)\n",
    "    print('char_data', char_data)\n",
    "    keep_rate = 1\n",
    "    print('aya')\n",
    "    \n",
    "    #print(char_data.shape)\n",
    "#The place holder to hold the values of new x and y at different times.\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[max_sequence_length, max_char_length * char_dimensions])\n",
    "    x = tf.cast(tf.reshape(char_data, shape=[max_sequence_length, max_char_length * char_dimensions]), dtype=tf.float32)\n",
    "    #print(x)\n",
    "#y = tf.placeholder('float', [batch_size, n_classes])\n",
    "\n",
    "    def embedding_layer(data):\n",
    "        print('aya')\n",
    "        l1 = tf.add(tf.tensordot(data,hidden_1_layer['weights'], axes=1), hidden_1_layer['biases'])\n",
    "        l1 = tf.nn.relu(l1)\n",
    "        print(l1.shape)\n",
    "        return l1\n",
    "\n",
    "    def conv2d(x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "    def maxpool2d(x):\n",
    "        #                        size of window         movement of window\n",
    "        return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "    def convolutional_neural_network(x):\n",
    "        \n",
    "#        tf.get_variable(\"W_conv1\", shape=([5,5,1,32]), dtype=tf.int32,\n",
    "#                      initializer=tf.ones_initializer())\n",
    "#                tf.get_variable(\"W_conv2\", shape=([5,5,32,64]), dtype=tf.int32,\n",
    "#                      initializer=tf.ones_initializer())\n",
    "#        \n",
    "#                        tf.get_variable(\"W_fc\", shape=([(int(max_char_length//4))*(int(char_dimensions//4))*64,1024]), dtype=tf.int32,\n",
    "#                      initializer=tf.ones_initializer())\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        print('og', x.shape)\n",
    "        x = tf.reshape(x, shape=[max_sequence_length,10,4, 1])\n",
    "        \n",
    "        conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "        conv2 = maxpool2d(conv1)\n",
    "\n",
    "        #conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "        #conv2 = maxpool2d(conv2)\n",
    "        \n",
    "        print('con2',conv2.shape)\n",
    "        fc = tf.reshape(conv2,[max_sequence_length, (10//2) * (4//2) * 32])\n",
    "        fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "        fc = tf.nn.dropout(fc, keep_rate)\n",
    "        #print(fc.shape)\n",
    "        return fc\n",
    "\n",
    "    def train_neural_network(x):    \n",
    "        embedded_x = embedding_layer(x)\n",
    "        print(embedded_x)\n",
    "        #embedded_x = tf.reshape(x, [max_sequence_length, char_dimensions])\n",
    "        convoluted_x = convolutional_neural_network(embedded_x)\n",
    "        \n",
    "        return convoluted_x\n",
    "    \n",
    "    char_data = train_neural_network(x)\n",
    "    return char_data\n",
    "\n",
    "\n",
    "char_input_data = tf.placeholder(dtype=tf.float32,shape= [batch_size, max_sequence_length, max_char_length])\n",
    "char_embeddings = tf.map_fn(lambda x: character_level_embedding(x), char_input_data, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "(100, 20, 100)\n"
     ]
    }
   ],
   "source": [
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    p = ids_char.astype(int)[100:200]\n",
    "    print(type(p[0][0][0]))\n",
    "    b = sess.run([char_embeddings], feed_dict={char_input_data: p})\n",
    "    print(b[0].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 2623, 14000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "epochs = 10\n",
    "numDimensions = 100\n",
    "batchSize = 100\n",
    "train_len = 14000\n",
    "\n",
    "X_train = ids[:train_len]\n",
    "y_train = y_list[:train_len]\n",
    "X_test = ids[train_len:]\n",
    "y_test = y_list[train_len:]\n",
    "ids_char_train = ids_char[:train_len]\n",
    "ids_char_test = ids_char[train_len:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test, ids_char_train, ids_char_test = train_test_split(ids,y_list,ids_char, test_size=.2)\n",
    "\n",
    "len(X_train), len(y_test), len(ids_char_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_train[i:i+batchSize]\n",
    "    labels = y_train[i:i+batchSize]\n",
    "    arr_char = ids_char_train[i:i+batchSize]\n",
    "    #print(labels[0])\n",
    "    return arr, labels, arr_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_test[i:i+batchSize]\n",
    "    labels =   y_test[i:i+batchSize]\n",
    "    arr_char = ids_char_test[i:i+batchSize]\n",
    "    return arr, labels, arr_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, [batchSize, max_sequence_length, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, max_sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = tf.convert_to_tensor(wordVectors, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 100)\n",
      "(100, 20, 100)\n"
     ]
    }
   ],
   "source": [
    "data = tf.placeholder(shape = (batchSize,max_sequence_length,numDimensions), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "print(data.shape)\n",
    "print(char_embeddings.shape)\n",
    "data2 = tf.placeholder(shape = (batchSize,max_sequence_length,numDimensions+char_dimensions), dtype=tf.float32)\n",
    "data2 = tf.concat([data, char_embeddings], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_cell3 = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])\n",
    "bw_cell3 = tf.nn.rnn_cell.MultiRNNCell([ tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs,value2 = tf.nn.bidirectional_dynamic_rnn(fw_cell3, bw_cell3,data2,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(outputs)\n",
    "\n",
    "outputs = tf.concat(outputs, 2)\n",
    "#print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits*2,numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[batchSize,max_sequence_length,numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20) (100, 20) (1271.0, 1271.0) (141.0, 141.0) (16.0, 16.0) (572.0, 572.0)\n"
     ]
    }
   ],
   "source": [
    "prediction = (tf.tensordot(outputs, weight, axes=((2,),(0,))) + bias)\n",
    "prediction_arg = tf.argmax(prediction,axis=2)\n",
    "label_arg = tf.argmax(labels,axis=2)\n",
    "#false_positives\n",
    "false_positives = tf.metrics.false_positives(predictions=prediction_arg, labels=label_arg)\n",
    "false_negatives = tf.metrics.false_negatives(predictions=prediction_arg, labels=label_arg)\n",
    "true_positives = tf.metrics.true_positives(predictions=prediction_arg, labels=label_arg)\n",
    "true_negatives = tf.metrics.true_negatives(predictions=prediction_arg, labels=label_arg)\n",
    "prec = tf.metrics.precision(predictions=prediction_arg, labels=label_arg)\n",
    "rec = tf.metrics.recall(predictions=prediction_arg, labels=label_arg)\n",
    "#false_positives = 1\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    #tf.initialize_all_variables().run()\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    nextBatch, nextBatchLabels, nextChars = getTrainBatch(2)\n",
    "        #print(j/2)\n",
    "    pred, pa, la, fp, fn, tp, tn = sess.run([prediction, prediction_arg, label_arg, false_positives, false_negatives, true_positives, true_negatives], {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "    print(pa.shape, la.shape, fp, fn, tp, tn)\n",
    "    #a = pred[0]\n",
    "    #b = nextBatchLabels\n",
    "   # print(a.shape,b.shape)\n",
    "    #print(a.shape)\n",
    "    #print(np.argmax(a, axis=2)[0])\n",
    "    #print(np.argmax(b, axis=2)[0])\n",
    "    #print(np.logical_and(np.argmax(a, axis=2)[0], np.argmax(b, axis=2)[0] ))\n",
    "    #print((np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2)))[0])\n",
    "    #print(np.mean(np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2)), axis=1))\n",
    "    #print(np.mean(np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2)), axis=0))\n",
    "    #print(np.mean(np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2))))\n",
    "correctPred = tf.equal(tf.argmax(prediction,axis=2), tf.argmax(labels,axis=2))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-297707c63317>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())#\n",
    "\n",
    "#    o,w,b,p = sess.run([outputs,weight,bias,prediction],feed_dict={input_data: X_train[:100], labels: y_train[:100]})\n",
    "#    print(np.array(o).shape,np.array(w).shape,np.array(b).shape,np.array(p).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "0.22077945\n",
      "0.2079053\n",
      "0.17454389\n",
      "0.13971573\n",
      "0.12849453\n",
      "0.1315633\n",
      "0.11414803\n",
      "0.12440036\n",
      "0.118587054\n",
      "0.11099576\n",
      "0.1072645\n",
      "0.10981804\n",
      "0.123527005\n",
      "0.1322864\n",
      "0.13841373\n",
      "0.14295293\n",
      "0.13181126\n",
      "0.1132085\n",
      "0.10921219\n",
      "0.09150968\n",
      "0.09737611\n",
      "0.09196541\n",
      "0.099539325\n",
      "0.08799392\n",
      "0.0806541\n",
      "0.096890815\n",
      "0.09422344\n",
      "0.07925818\n",
      "0.07951962\n",
      "0.08558659\n",
      "0.09311615\n",
      "0.08632106\n",
      "0.11144341\n",
      "0.1092793\n",
      "0.09926801\n",
      "0.09121412\n",
      "0.07606805\n",
      "0.08857037\n",
      "0.084300004\n",
      "0.077371344\n",
      "0.07729346\n",
      "0.06677896\n",
      "0.07399739\n",
      "0.08184701\n",
      "0.08593546\n",
      "0.08356258\n",
      "0.07079471\n",
      "0.073426254\n",
      "0.07757882\n",
      "0.061349183\n",
      "0.107784025\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "0.108862124\n",
      "0.11754665\n",
      "0.08713851\n",
      "0.09493377\n",
      "0.103688315\n",
      "0.10630881\n",
      "0.08064293\n",
      "0.123865396\n",
      "0.08263768\n",
      "0.11945187\n",
      "0.108031236\n",
      "0.10362485\n",
      "0.10866069\n",
      "0.07171677\n",
      "0.07799322\n",
      "0.092167616\n",
      "0.08006952\n",
      "0.0841776\n",
      "0.101558045\n",
      "0.077029236\n",
      "0.0940962\n",
      "0.0836927\n",
      "0.088007\n",
      "0.06588414\n",
      "0.06375694\n",
      "0.07214543\n",
      "0.07390483\n",
      "0.06877568\n",
      "0.05849323\n",
      "0.07131946\n",
      "0.070278674\n",
      "0.07217214\n",
      "0.07456344\n",
      "0.06357213\n",
      "0.066143885\n",
      "0.064730026\n",
      "0.104705475\n",
      "0.088308625\n",
      "0.098811164\n",
      "0.08636354\n",
      "0.068426184\n",
      "0.058119487\n",
      "0.065045886\n",
      "0.05995985\n",
      "0.07321845\n",
      "0.08574619\n",
      "0.0562875\n",
      "0.05698458\n",
      "0.07682908\n",
      "0.06676949\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "0.07668364\n",
      "0.065773666\n",
      "0.06456288\n",
      "0.07220616\n",
      "0.09738259\n",
      "0.084066056\n",
      "0.08735281\n",
      "0.05816518\n",
      "0.05930107\n",
      "0.060422827\n",
      "0.06113497\n",
      "0.06328338\n",
      "0.061155044\n",
      "0.069815904\n",
      "0.059471928\n",
      "0.055480096\n",
      "0.06333036\n",
      "0.060626294\n",
      "0.07614473\n",
      "0.086453065\n",
      "0.08011915\n",
      "0.06522349\n",
      "0.08383747\n",
      "0.05360104\n",
      "0.07248094\n",
      "0.048186038\n",
      "0.057204917\n",
      "0.053019796\n",
      "0.07682968\n",
      "0.10800005\n",
      "0.09345677\n",
      "0.096035495\n",
      "0.10543794\n",
      "0.059887733\n",
      "0.07166103\n",
      "0.074548274\n",
      "0.07002905\n",
      "0.059045058\n",
      "0.058187768\n",
      "12.238265465945005\n",
      "epoch:  1\n",
      "0.07753519\n",
      "0.07850303\n",
      "0.049167644\n",
      "0.051075395\n",
      "0.053657502\n",
      "0.065809384\n",
      "0.046967477\n",
      "0.055619422\n",
      "0.064055905\n",
      "0.050856642\n",
      "0.045456186\n",
      "0.06475813\n",
      "0.05781542\n",
      "0.0836792\n",
      "0.066323005\n",
      "0.07726923\n",
      "0.08047315\n",
      "0.07219824\n",
      "0.06673086\n",
      "0.051914155\n",
      "0.06328686\n",
      "0.05822086\n",
      "0.06653621\n",
      "0.05322899\n",
      "0.052424546\n",
      "0.0521774\n",
      "0.066913776\n",
      "0.049608544\n",
      "0.051858738\n",
      "0.059398886\n",
      "0.06338684\n",
      "0.05571051\n",
      "0.082178175\n",
      "0.08424081\n",
      "0.071762264\n",
      "0.058422066\n",
      "0.05859355\n",
      "0.075165555\n",
      "0.055798195\n",
      "0.05639571\n",
      "0.059302583\n",
      "0.04932909\n",
      "0.053292222\n",
      "0.054442625\n",
      "0.06299006\n",
      "0.06623281\n",
      "0.05552439\n",
      "0.057290368\n",
      "0.062303953\n",
      "0.04523291\n",
      "0.07779177\n",
      "saved to models/pretrained_lstm.ckpt-1\n",
      "0.07339948\n",
      "0.080863446\n",
      "0.060726594\n",
      "0.06842637\n",
      "0.06529664\n",
      "0.08347183\n",
      "0.055955518\n",
      "0.07512017\n",
      "0.055702783\n",
      "0.071607724\n",
      "0.06588081\n",
      "0.07382686\n",
      "0.08750821\n",
      "0.055794686\n",
      "0.059462808\n",
      "0.08003503\n",
      "0.070313096\n",
      "0.07364479\n",
      "0.098411456\n",
      "0.06693013\n",
      "0.08838626\n",
      "0.073763154\n",
      "0.069474794\n",
      "0.055871964\n",
      "0.053978775\n",
      "0.072564885\n",
      "0.066027954\n",
      "0.062947094\n",
      "0.05013723\n",
      "0.06363381\n",
      "0.06514465\n",
      "0.06399821\n",
      "0.066369586\n",
      "0.060940612\n",
      "0.06394912\n",
      "0.059044518\n",
      "0.10233783\n",
      "0.08147592\n",
      "0.09027707\n",
      "0.08450968\n",
      "0.07150332\n",
      "0.057282876\n",
      "0.064230785\n",
      "0.054353278\n",
      "0.06727246\n",
      "0.076699786\n",
      "0.054645043\n",
      "0.052209746\n",
      "0.07019791\n",
      "0.06440358\n",
      "saved to models/pretrained_lstm.ckpt-1\n",
      "0.080847405\n",
      "0.057094507\n",
      "0.06403412\n",
      "0.07174823\n",
      "0.08883572\n",
      "0.07405209\n",
      "0.0850788\n",
      "0.05771191\n",
      "0.05817939\n",
      "0.058388136\n",
      "0.061020706\n",
      "0.064054206\n",
      "0.060397882\n",
      "0.06685327\n",
      "0.0533953\n",
      "0.046371575\n",
      "0.056511153\n",
      "0.056813933\n",
      "0.06964184\n",
      "0.08529322\n",
      "0.078838624\n",
      "0.0628695\n",
      "0.07348592\n",
      "0.045594703\n",
      "0.061651725\n",
      "0.04954196\n",
      "0.055696357\n",
      "0.049386702\n",
      "0.070851214\n",
      "0.09387395\n",
      "0.08676801\n",
      "0.08765619\n",
      "0.09086001\n",
      "0.05178172\n",
      "0.06585629\n",
      "0.06357083\n",
      "0.061154757\n",
      "0.056501474\n",
      "0.052072655\n",
      "9.163252733647823\n",
      "epoch:  2\n",
      "0.07189203\n",
      "0.072081104\n",
      "0.045509942\n",
      "0.043379616\n",
      "0.04851777\n",
      "0.06270074\n",
      "0.044426415\n",
      "0.05168036\n",
      "0.0637143\n",
      "0.043247372\n",
      "0.046375938\n",
      "0.06186941\n",
      "0.054655332\n",
      "0.072841056\n",
      "0.06385444\n",
      "0.072657764\n",
      "0.07848431\n",
      "0.06619677\n",
      "0.05558294\n",
      "0.047279008\n",
      "0.059083387\n",
      "0.056221154\n",
      "0.057337623\n",
      "0.04623852\n",
      "0.051335033\n",
      "0.047271285\n",
      "0.06245529\n",
      "0.04876543\n",
      "0.04620635\n",
      "0.051239144\n",
      "0.056700706\n",
      "0.05479174\n",
      "0.071774\n",
      "0.077527404\n",
      "0.065575436\n",
      "0.05574806\n",
      "0.05540355\n",
      "0.070431285\n",
      "0.054388642\n",
      "0.0488617\n",
      "0.053310815\n",
      "0.05310395\n",
      "0.053498656\n",
      "0.054994375\n",
      "0.058936205\n",
      "0.067073874\n",
      "0.05054734\n",
      "0.055709325\n",
      "0.059469577\n",
      "0.042371046\n",
      "0.07032994\n",
      "saved to models/pretrained_lstm.ckpt-2\n",
      "0.06751576\n",
      "0.07395518\n",
      "0.060410075\n",
      "0.0665246\n",
      "0.05866596\n",
      "0.07280665\n",
      "0.05364858\n",
      "0.06917301\n",
      "0.057733186\n",
      "0.066021904\n",
      "0.064542525\n",
      "0.07064586\n",
      "0.07647105\n",
      "0.059143648\n",
      "0.06263873\n",
      "0.06925507\n",
      "0.06514888\n",
      "0.07150009\n",
      "0.090585954\n",
      "0.06278186\n",
      "0.0774037\n",
      "0.07345207\n",
      "0.07819866\n",
      "0.05073055\n",
      "0.052727204\n",
      "0.059161454\n",
      "0.05853813\n",
      "0.056262128\n",
      "0.04133143\n",
      "0.06269066\n",
      "0.0658742\n",
      "0.061228745\n",
      "0.064665675\n",
      "0.05301871\n",
      "0.05834657\n",
      "0.053942356\n",
      "0.08534958\n",
      "0.0778521\n",
      "0.12405694\n",
      "0.10211853\n",
      "0.07715637\n",
      "0.052729577\n",
      "0.056393966\n",
      "0.056398913\n",
      "0.07370914\n",
      "0.07694594\n",
      "0.053856358\n",
      "0.055639777\n",
      "0.07485225\n",
      "0.073869094\n",
      "saved to models/pretrained_lstm.ckpt-2\n",
      "0.06446685\n",
      "0.06353485\n",
      "0.069292426\n",
      "0.06781363\n",
      "0.08625786\n",
      "0.074498154\n",
      "0.08620138\n",
      "0.057716195\n",
      "0.051726248\n",
      "0.06012204\n",
      "0.058397964\n",
      "0.05301211\n",
      "0.05174549\n",
      "0.06335352\n",
      "0.05653544\n",
      "0.05128939\n",
      "0.06681325\n",
      "0.056269556\n",
      "0.062680416\n",
      "0.08137782\n",
      "0.07229623\n",
      "0.05946487\n",
      "0.067669235\n",
      "0.045967724\n",
      "0.07056442\n",
      "0.040694658\n",
      "0.047298443\n",
      "0.05268464\n",
      "0.06465436\n",
      "0.09196627\n",
      "0.07987676\n",
      "0.082624815\n",
      "0.0863436\n",
      "0.04984252\n",
      "0.07006366\n",
      "0.061496027\n",
      "0.052912705\n",
      "0.052862287\n",
      "0.056534957\n",
      "8.760239586234093\n",
      "epoch:  3\n",
      "0.06942976\n",
      "0.071453854\n",
      "0.045288026\n",
      "0.045503043\n",
      "0.051667955\n",
      "0.0635605\n",
      "0.038977377\n",
      "0.054010514\n",
      "0.06275671\n",
      "0.04321836\n",
      "0.042193327\n",
      "0.056881867\n",
      "0.0584834\n",
      "0.06668737\n",
      "0.056527775\n",
      "0.0746646\n",
      "0.08140143\n",
      "0.062861234\n",
      "0.055211388\n",
      "0.04578216\n",
      "0.05912687\n",
      "0.05568396\n",
      "0.06251225\n",
      "0.049089026\n",
      "0.052102923\n",
      "0.049922206\n",
      "0.06001753\n",
      "0.042283263\n",
      "0.04610096\n",
      "0.057350144\n",
      "0.061598938\n",
      "0.05622441\n",
      "0.0798376\n",
      "0.07139282\n",
      "0.06605042\n",
      "0.05687446\n",
      "0.057829317\n",
      "0.07808688\n",
      "0.04990201\n",
      "0.04926329\n",
      "0.054789044\n",
      "0.05243064\n",
      "0.051609\n",
      "0.054599326\n",
      "0.06364825\n",
      "0.06109523\n",
      "0.048213042\n",
      "0.0536402\n",
      "0.053994033\n",
      "0.04183433\n",
      "0.0669677\n",
      "saved to models/pretrained_lstm.ckpt-3\n",
      "0.06415889\n",
      "0.06716246\n",
      "0.059336804\n",
      "0.063844845\n",
      "0.05746027\n",
      "0.069054075\n",
      "0.053450853\n",
      "0.07103888\n",
      "0.05535329\n",
      "0.06737751\n",
      "0.057229266\n",
      "0.06993252\n",
      "0.07652668\n",
      "0.054754946\n",
      "0.05894428\n",
      "0.0739932\n",
      "0.06270194\n",
      "0.07407899\n",
      "0.08365423\n",
      "0.06708346\n",
      "0.07382254\n",
      "0.06325082\n",
      "0.06704335\n",
      "0.0477175\n",
      "0.05097162\n",
      "0.053418078\n",
      "0.0597458\n",
      "0.05143844\n",
      "0.042601205\n",
      "0.057356372\n",
      "0.059468035\n",
      "0.058227897\n",
      "0.061742045\n",
      "0.05249875\n",
      "0.051060762\n",
      "0.050898477\n",
      "0.08350046\n",
      "0.07482301\n",
      "0.0853456\n",
      "0.06766772\n",
      "0.06800293\n",
      "0.049224418\n",
      "0.054468933\n",
      "0.045337047\n",
      "0.06897031\n",
      "0.0717334\n",
      "0.043621488\n",
      "0.044660866\n",
      "0.056451246\n",
      "0.058437396\n",
      "saved to models/pretrained_lstm.ckpt-3\n",
      "0.063259706\n",
      "0.050564583\n",
      "0.057523042\n",
      "0.06532786\n",
      "0.07914446\n",
      "0.06622018\n",
      "0.0794729\n",
      "0.0541834\n",
      "0.049726278\n",
      "0.051468216\n",
      "0.057221893\n",
      "0.05040605\n",
      "0.04677814\n",
      "0.05951888\n",
      "0.050345875\n",
      "0.042438895\n",
      "0.054858595\n",
      "0.05054387\n",
      "0.05833015\n",
      "0.07574568\n",
      "0.07200583\n",
      "0.056951076\n",
      "0.065608114\n",
      "0.042298134\n",
      "0.059362035\n",
      "0.036869947\n",
      "0.042701848\n",
      "0.048434716\n",
      "0.059412125\n",
      "0.09234634\n",
      "0.07491683\n",
      "0.07333644\n",
      "0.07915581\n",
      "0.04610872\n",
      "0.057674102\n",
      "0.05549326\n",
      "0.053563546\n",
      "0.04700398\n",
      "0.05605544\n",
      "8.273651588708162\n",
      "epoch:  4\n",
      "0.06619139\n",
      "0.06346099\n",
      "0.04173766\n",
      "0.04236847\n",
      "0.045875672\n",
      "0.053264968\n",
      "0.038279474\n",
      "0.0502927\n",
      "0.059622552\n",
      "0.043216124\n",
      "0.03962013\n",
      "0.05230574\n",
      "0.05207637\n",
      "0.06477052\n",
      "0.05147759\n",
      "0.06525759\n",
      "0.07585802\n",
      "0.061834008\n",
      "0.051412717\n",
      "0.041128915\n",
      "0.056861993\n",
      "0.051929116\n",
      "0.05409881\n",
      "0.04592121\n",
      "0.044775054\n",
      "0.047547232\n",
      "0.053729016\n",
      "0.037645053\n",
      "0.046785735\n",
      "0.05449569\n",
      "0.05659785\n",
      "0.047858436\n",
      "0.0696026\n",
      "0.070908055\n",
      "0.06262833\n",
      "0.051449906\n",
      "0.049419876\n",
      "0.07113088\n",
      "0.05103133\n",
      "0.05041471\n",
      "0.04918544\n",
      "0.0439335\n",
      "0.0500136\n",
      "0.045304462\n",
      "0.055577666\n",
      "0.058821037\n",
      "0.049437843\n",
      "0.052250557\n",
      "0.05076477\n",
      "0.0404448\n",
      "0.06774071\n",
      "saved to models/pretrained_lstm.ckpt-4\n",
      "0.06040774\n",
      "0.06668098\n",
      "0.053471364\n",
      "0.061249588\n",
      "0.054292407\n",
      "0.07008768\n",
      "0.05000135\n",
      "0.06676224\n",
      "0.053247314\n",
      "0.060106553\n",
      "0.056032874\n",
      "0.06652979\n",
      "0.06906654\n",
      "0.047907002\n",
      "0.054551106\n",
      "0.06754258\n",
      "0.060417876\n",
      "0.06782335\n",
      "0.08673345\n",
      "0.060346406\n",
      "0.06734628\n",
      "0.05869951\n",
      "0.060129583\n",
      "0.052947138\n",
      "0.05432561\n",
      "0.04897167\n",
      "0.05186188\n",
      "0.051954232\n",
      "0.042033385\n",
      "0.061600782\n",
      "0.05864353\n",
      "0.054272827\n",
      "0.060729887\n",
      "0.05281968\n",
      "0.05172052\n",
      "0.05389251\n",
      "0.08089389\n",
      "0.071009375\n",
      "0.08246467\n",
      "0.068322524\n",
      "0.06635151\n",
      "0.0468004\n",
      "0.054832686\n",
      "0.04862404\n",
      "0.063915044\n",
      "0.07301213\n",
      "0.044168044\n",
      "0.048264403\n",
      "0.065165326\n",
      "0.061505243\n",
      "saved to models/pretrained_lstm.ckpt-4\n",
      "0.06511746\n",
      "0.05102327\n",
      "0.06114391\n",
      "0.06319573\n",
      "0.07817685\n",
      "0.061864685\n",
      "0.07129001\n",
      "0.054279633\n",
      "0.049694635\n",
      "0.04950909\n",
      "0.054473106\n",
      "0.052856907\n",
      "0.051123627\n",
      "0.057139564\n",
      "0.048752245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04101217\n",
      "0.05459471\n",
      "0.049191687\n",
      "0.05452784\n",
      "0.06804218\n",
      "0.06725864\n",
      "0.052407604\n",
      "0.062228035\n",
      "0.039438773\n",
      "0.05831528\n",
      "0.037880927\n",
      "0.04111662\n",
      "0.047219787\n",
      "0.05724633\n",
      "0.0835381\n",
      "0.069832854\n",
      "0.069483764\n",
      "0.073296905\n",
      "0.046865035\n",
      "0.05667099\n",
      "0.053862352\n",
      "0.052591063\n",
      "0.045131523\n",
      "0.052281976\n",
      "7.892569240182638\n",
      "epoch:  5\n",
      "0.055475593\n",
      "0.06051732\n",
      "0.041357104\n",
      "0.040551536\n",
      "0.044756353\n",
      "0.05066317\n",
      "0.032651626\n",
      "0.04297171\n",
      "0.05698242\n",
      "0.039838854\n",
      "0.040355835\n",
      "0.053466756\n",
      "0.050274882\n",
      "0.06054562\n",
      "0.054320667\n",
      "0.06306381\n",
      "0.080338985\n",
      "0.05857817\n",
      "0.05122534\n",
      "0.03715214\n",
      "0.055958115\n",
      "0.04705893\n",
      "0.052979268\n",
      "0.043031685\n",
      "0.04233517\n",
      "0.04260438\n",
      "0.05311411\n",
      "0.038414273\n",
      "0.049201895\n",
      "0.050634533\n",
      "0.049663503\n",
      "0.048134718\n",
      "0.07596933\n",
      "0.07091548\n",
      "0.054985225\n",
      "0.04995192\n",
      "0.04909318\n",
      "0.06764825\n",
      "0.048914753\n",
      "0.045591734\n",
      "0.048335996\n",
      "0.03874527\n",
      "0.048820216\n",
      "0.04245298\n",
      "0.05155852\n",
      "0.053885248\n",
      "0.04264885\n",
      "0.050497103\n",
      "0.04699594\n",
      "0.039298493\n",
      "0.056368653\n",
      "saved to models/pretrained_lstm.ckpt-5\n",
      "0.06018896\n",
      "0.06258185\n",
      "0.051159203\n",
      "0.058256194\n",
      "0.052015863\n",
      "0.069930375\n",
      "0.052605912\n",
      "0.064484775\n",
      "0.05148234\n",
      "0.05996827\n",
      "0.054086525\n",
      "0.0678709\n",
      "0.06427435\n",
      "0.047498453\n",
      "0.05476493\n",
      "0.06759827\n",
      "0.05535626\n",
      "0.06435735\n",
      "0.08292657\n",
      "0.058165547\n",
      "0.06812135\n",
      "0.053844336\n",
      "0.060348015\n",
      "0.052174598\n",
      "0.05034096\n",
      "0.055391718\n",
      "0.049763553\n",
      "0.04540078\n",
      "0.041300073\n",
      "0.055073388\n",
      "0.056634925\n",
      "0.04870147\n",
      "0.060319174\n",
      "0.051154274\n",
      "0.051566534\n",
      "0.046116117\n",
      "0.07770135\n",
      "0.07078335\n",
      "0.08001146\n",
      "0.06505174\n",
      "0.05885127\n",
      "0.042683333\n",
      "0.04968183\n",
      "0.04520029\n",
      "0.056205425\n",
      "0.06893523\n",
      "0.03877533\n",
      "0.04159172\n",
      "0.064311236\n",
      "0.059407886\n",
      "saved to models/pretrained_lstm.ckpt-5\n",
      "0.060355656\n",
      "0.04816298\n",
      "0.05326902\n",
      "0.060540933\n",
      "0.07615235\n",
      "0.058104694\n",
      "0.06556257\n",
      "0.047841094\n",
      "0.04573193\n",
      "0.050275568\n",
      "0.05223365\n",
      "0.046900366\n",
      "0.047579788\n",
      "0.06046079\n",
      "0.04810183\n",
      "0.040368497\n",
      "0.05064459\n",
      "0.047637727\n",
      "0.05420577\n",
      "0.06592783\n",
      "0.07408139\n",
      "0.057215046\n",
      "0.06287092\n",
      "0.0417876\n",
      "0.055680517\n",
      "0.036190223\n",
      "0.04541485\n",
      "0.048151765\n",
      "0.059632175\n",
      "0.0778246\n",
      "0.07104398\n",
      "0.07470834\n",
      "0.07572509\n",
      "0.04361776\n",
      "0.058377493\n",
      "0.05470259\n",
      "0.047289755\n",
      "0.04808689\n",
      "0.049490828\n",
      "7.597860671579838\n",
      "epoch:  6\n",
      "0.058588963\n",
      "0.06318576\n",
      "0.039949782\n",
      "0.04300945\n",
      "0.046446912\n",
      "0.049826723\n",
      "0.036360405\n",
      "0.045509294\n",
      "0.055448413\n",
      "0.036442205\n",
      "0.041514687\n",
      "0.059654832\n",
      "0.051764514\n",
      "0.06068413\n",
      "0.048841447\n",
      "0.06667785\n",
      "0.07866996\n",
      "0.0550891\n",
      "0.05576703\n",
      "0.03738208\n",
      "0.054577656\n",
      "0.04913171\n",
      "0.0524713\n",
      "0.043224283\n",
      "0.041551657\n",
      "0.04215917\n",
      "0.05318149\n",
      "0.0370682\n",
      "0.040374015\n",
      "0.052214097\n",
      "0.047372613\n",
      "0.04492411\n",
      "0.06900891\n",
      "0.06474776\n",
      "0.053480722\n",
      "0.047368675\n",
      "0.045470085\n",
      "0.06708119\n",
      "0.05607191\n",
      "0.044555124\n",
      "0.04771807\n",
      "0.040238358\n",
      "0.049674574\n",
      "0.04721638\n",
      "0.05449011\n",
      "0.05651032\n",
      "0.04517937\n",
      "0.050182942\n",
      "0.04777254\n",
      "0.035949823\n",
      "0.056465343\n",
      "saved to models/pretrained_lstm.ckpt-6\n",
      "0.055493295\n",
      "0.061656646\n",
      "0.051753964\n",
      "0.061976038\n",
      "0.04957957\n",
      "0.06776866\n",
      "0.048137706\n",
      "0.06298542\n",
      "0.048826262\n",
      "0.05458979\n",
      "0.055118747\n",
      "0.07059077\n",
      "0.062841445\n",
      "0.049275152\n",
      "0.053549737\n",
      "0.06608819\n",
      "0.062672414\n",
      "0.066988714\n",
      "0.08577281\n",
      "0.057204522\n",
      "0.06404796\n",
      "0.05203134\n",
      "0.060655702\n",
      "0.048457053\n",
      "0.048350394\n",
      "0.047994908\n",
      "0.04811471\n",
      "0.04241256\n",
      "0.042785224\n",
      "0.054697428\n",
      "0.052774895\n",
      "0.05012307\n",
      "0.05974185\n",
      "0.048947863\n",
      "0.0501443\n",
      "0.044330623\n",
      "0.077606894\n",
      "0.067271546\n",
      "0.07962343\n",
      "0.06425063\n",
      "0.060504965\n",
      "0.04342184\n",
      "0.05050739\n",
      "0.04009182\n",
      "0.054557793\n",
      "0.067276016\n",
      "0.040624563\n",
      "0.0434452\n",
      "0.060964353\n",
      "0.055781018\n",
      "saved to models/pretrained_lstm.ckpt-6\n",
      "0.057598207\n",
      "0.04158392\n",
      "0.051759\n",
      "0.056510985\n",
      "0.07799757\n",
      "0.06100469\n",
      "0.06549739\n",
      "0.04915456\n",
      "0.053218532\n",
      "0.048077125\n",
      "0.0443463\n",
      "0.047729637\n",
      "0.040350296\n",
      "0.053364187\n",
      "0.042677697\n",
      "0.037484523\n",
      "0.046661936\n",
      "0.0469076\n",
      "0.049808268\n",
      "0.06274155\n",
      "0.0685927\n",
      "0.048951164\n",
      "0.060784385\n",
      "0.03722817\n",
      "0.057093117\n",
      "0.03980635\n",
      "0.04356548\n",
      "0.045148976\n",
      "0.054613557\n",
      "0.08188297\n",
      "0.06923463\n",
      "0.07037386\n",
      "0.07056984\n",
      "0.03941622\n",
      "0.058712885\n",
      "0.051538505\n",
      "0.044400558\n",
      "0.041612137\n",
      "0.048446458\n",
      "7.449099190533161\n",
      "epoch:  7\n",
      "0.05328006\n",
      "0.053535677\n",
      "0.037014782\n",
      "0.039378062\n",
      "0.04596544\n",
      "0.051600426\n",
      "0.031902116\n",
      "0.048036117\n",
      "0.05830081\n",
      "0.038954113\n",
      "0.036398865\n",
      "0.054126933\n",
      "0.047023207\n",
      "0.05508317\n",
      "0.044644285\n",
      "0.065934055\n",
      "0.07390385\n",
      "0.054101653\n",
      "0.050820917\n",
      "0.037029427\n",
      "0.048233405\n",
      "0.051504344\n",
      "0.04669752\n",
      "0.04410219\n",
      "0.04062754\n",
      "0.035957176\n",
      "0.050285682\n",
      "0.03244704\n",
      "0.04013901\n",
      "0.045017637\n",
      "0.045007087\n",
      "0.04846988\n",
      "0.06514854\n",
      "0.059380457\n",
      "0.048744034\n",
      "0.044645797\n",
      "0.049402785\n",
      "0.066403925\n",
      "0.04738754\n",
      "0.041130904\n",
      "0.04238928\n",
      "0.036818236\n",
      "0.049155146\n",
      "0.04319868\n",
      "0.05092447\n",
      "0.05634215\n",
      "0.04151677\n",
      "0.04737723\n",
      "0.042531293\n",
      "0.037577294\n",
      "0.055327874\n",
      "saved to models/pretrained_lstm.ckpt-7\n",
      "0.05091909\n",
      "0.056884587\n",
      "0.050328746\n",
      "0.053309564\n",
      "0.044737615\n",
      "0.06475273\n",
      "0.046155524\n",
      "0.05912673\n",
      "0.052015364\n",
      "0.055392127\n",
      "0.047641285\n",
      "0.06392593\n",
      "0.059630796\n",
      "0.045704845\n",
      "0.0480678\n",
      "0.060904555\n",
      "0.059050936\n",
      "0.061819192\n",
      "0.079469025\n",
      "0.051547423\n",
      "0.06275493\n",
      "0.04881457\n",
      "0.06234572\n",
      "0.04886818\n",
      "0.04659132\n",
      "0.04450437\n",
      "0.046980184\n",
      "0.041451458\n",
      "0.041105155\n",
      "0.057444543\n",
      "0.049420822\n",
      "0.04684255\n",
      "0.05853334\n",
      "0.049288806\n",
      "0.047530312\n",
      "0.047976606\n",
      "0.07807562\n",
      "0.06516433\n",
      "0.074935175\n",
      "0.0692359\n",
      "0.06726517\n",
      "0.039869376\n",
      "0.048776474\n",
      "0.040358588\n",
      "0.05863209\n",
      "0.064948946\n",
      "0.039903507\n",
      "0.036942508\n",
      "0.04886757\n",
      "0.056174845\n",
      "saved to models/pretrained_lstm.ckpt-7\n",
      "0.060600165\n",
      "0.038869604\n",
      "0.05329594\n",
      "0.052988146\n",
      "0.0768421\n",
      "0.061066452\n",
      "0.060372707\n",
      "0.04600452\n",
      "0.04458789\n",
      "0.048546895\n",
      "0.044711854\n",
      "0.045291215\n",
      "0.04160413\n",
      "0.049878173\n",
      "0.04339904\n",
      "0.03800713\n",
      "0.045909982\n",
      "0.04831335\n",
      "0.048844106\n",
      "0.058958273\n",
      "0.06319005\n",
      "0.04709434\n",
      "0.05952555\n",
      "0.038295463\n",
      "0.05615827\n",
      "0.035156272\n",
      "0.037525453\n",
      "0.039321706\n",
      "0.051041998\n",
      "0.07680632\n",
      "0.064871594\n",
      "0.069382966\n",
      "0.06896369\n",
      "0.039622635\n",
      "0.058521684\n",
      "0.046311434\n",
      "0.03883733\n",
      "0.04121409\n",
      "0.044873394\n",
      "7.116717606782913\n",
      "epoch:  8\n",
      "0.049437437\n",
      "0.047916085\n",
      "0.03505165\n",
      "0.03805226\n",
      "0.041841485\n",
      "0.042188738\n",
      "0.033678755\n",
      "0.043321934\n",
      "0.055511057\n",
      "0.034736738\n",
      "0.03241957\n",
      "0.051139947\n",
      "0.04690284\n",
      "0.060674593\n",
      "0.04964715\n",
      "0.061981536\n",
      "0.06980982\n",
      "0.05094685\n",
      "0.047667045\n",
      "0.035465986\n",
      "0.043383583\n",
      "0.045920487\n",
      "0.041198358\n",
      "0.04041179\n",
      "0.039501235\n",
      "0.035283662\n",
      "0.046923805\n",
      "0.031414554\n",
      "0.03824464\n",
      "0.042628236\n",
      "0.044049095\n",
      "0.045053903\n",
      "0.061522897\n",
      "0.05752827\n",
      "0.049762696\n",
      "0.04091713\n",
      "0.051070787\n",
      "0.071748294\n",
      "0.045594964\n",
      "0.041599046\n",
      "0.0432249\n",
      "0.042131606\n",
      "0.041783392\n",
      "0.044344787\n",
      "0.05361147\n",
      "0.05302443\n",
      "0.039891403\n",
      "0.04578569\n",
      "0.043171458\n",
      "0.033695914\n",
      "0.051547814\n",
      "saved to models/pretrained_lstm.ckpt-8\n",
      "0.057432838\n",
      "0.057558272\n",
      "0.047992583\n",
      "0.059194274\n",
      "0.046581153\n",
      "0.061431427\n",
      "0.049195983\n",
      "0.062571816\n",
      "0.044729274\n",
      "0.05307859\n",
      "0.051342864\n",
      "0.064528145\n",
      "0.05277767\n",
      "0.04565165\n",
      "0.048762593\n",
      "0.06161005\n",
      "0.054972213\n",
      "0.06316157\n",
      "0.079035\n",
      "0.052516405\n",
      "0.06189208\n",
      "0.04724603\n",
      "0.057851214\n",
      "0.0459488\n",
      "0.0487187\n",
      "0.044704504\n",
      "0.04612278\n",
      "0.042167783\n",
      "0.039750796\n",
      "0.05536062\n",
      "0.049184892\n",
      "0.048541483\n",
      "0.056809038\n",
      "0.04571207\n",
      "0.043842163\n",
      "0.04762062\n",
      "0.0676292\n",
      "0.058763787\n",
      "0.0698733\n",
      "0.05989328\n",
      "0.057357736\n",
      "0.04346062\n",
      "0.04725417\n",
      "0.04033985\n",
      "0.055469263\n",
      "0.06688024\n",
      "0.040095504\n",
      "0.036191802\n",
      "0.05019813\n",
      "0.051942673\n",
      "saved to models/pretrained_lstm.ckpt-8\n",
      "0.057626396\n",
      "0.03954737\n",
      "0.04747412\n",
      "0.05739086\n",
      "0.07167595\n",
      "0.05548951\n",
      "0.06135469\n",
      "0.047908507\n",
      "0.04535461\n",
      "0.043371182\n",
      "0.044445418\n",
      "0.045239434\n",
      "0.041520648\n",
      "0.04713364\n",
      "0.041226793\n",
      "0.0361622\n",
      "0.047401015\n",
      "0.044358615\n",
      "0.047262244\n",
      "0.05863882\n",
      "0.0625729\n",
      "0.050668072\n",
      "0.057244506\n",
      "0.03434315\n",
      "0.049698975\n",
      "0.032618348\n",
      "0.03499264\n",
      "0.0398127\n",
      "0.055273313\n",
      "0.07570555\n",
      "0.06560864\n",
      "0.07007779\n",
      "0.065579414\n",
      "0.04192334\n",
      "0.054892\n",
      "0.05043514\n",
      "0.03654773\n",
      "0.04200809\n",
      "0.04642682\n",
      "6.922320403158665\n",
      "epoch:  9\n",
      "0.050613448\n",
      "0.046848502\n",
      "0.03819109\n",
      "0.040093515\n",
      "0.04307116\n",
      "0.049858745\n",
      "0.033823874\n",
      "0.046801385\n",
      "0.053497862\n",
      "0.03411839\n",
      "0.03532801\n",
      "0.050980773\n",
      "0.042065922\n",
      "0.06210829\n",
      "0.051115386\n",
      "0.06194674\n",
      "0.067101136\n",
      "0.048102096\n",
      "0.048799623\n",
      "0.039947044\n",
      "0.04830486\n",
      "0.046327658\n",
      "0.043801483\n",
      "0.043431893\n",
      "0.03957233\n",
      "0.035643533\n",
      "0.049472593\n",
      "0.035316166\n",
      "0.04078295\n",
      "0.043710504\n",
      "0.04369653\n",
      "0.046570178\n",
      "0.058232076\n",
      "0.058891296\n",
      "0.04727233\n",
      "0.03808375\n",
      "0.053859733\n",
      "0.062266577\n",
      "0.04551275\n",
      "0.0390758\n",
      "0.040107053\n",
      "0.038110033\n",
      "0.042293318\n",
      "0.045082733\n",
      "0.048176795\n",
      "0.051548377\n",
      "0.04498237\n",
      "0.048819657\n",
      "0.043608505\n",
      "0.035506576\n",
      "0.05512667\n",
      "saved to models/pretrained_lstm.ckpt-9\n",
      "0.05723062\n",
      "0.055966742\n",
      "0.048582446\n",
      "0.054933183\n",
      "0.042281594\n",
      "0.06352746\n",
      "0.04778653\n",
      "0.059816707\n",
      "0.04525165\n",
      "0.051944107\n",
      "0.050863642\n",
      "0.058657866\n",
      "0.057932008\n",
      "0.041337587\n",
      "0.04673749\n",
      "0.06310646\n",
      "0.05242679\n",
      "0.062137783\n",
      "0.07642037\n",
      "0.0531801\n",
      "0.05991482\n",
      "0.046775468\n",
      "0.05927035\n",
      "0.045104764\n",
      "0.051350936\n",
      "0.051007163\n",
      "0.0454616\n",
      "0.04456964\n",
      "0.041501097\n",
      "0.05495415\n",
      "0.05078379\n",
      "0.04881019\n",
      "0.055205673\n",
      "0.052042667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046045203\n",
      "0.041784573\n",
      "0.067944676\n",
      "0.063287735\n",
      "0.06746902\n",
      "0.06018025\n",
      "0.05675115\n",
      "0.044037905\n",
      "0.0479695\n",
      "0.04169403\n",
      "0.052667666\n",
      "0.06358591\n",
      "0.03735791\n",
      "0.036933966\n",
      "0.049265314\n",
      "0.05473896\n",
      "saved to models/pretrained_lstm.ckpt-9\n",
      "0.05478038\n",
      "0.036486648\n",
      "0.049497306\n",
      "0.05435021\n",
      "0.07032792\n",
      "0.054071788\n",
      "0.058704596\n",
      "0.04399711\n",
      "0.041031547\n",
      "0.04328978\n",
      "0.043903522\n",
      "0.044675425\n",
      "0.040149543\n",
      "0.048533287\n",
      "0.03910944\n",
      "0.03230123\n",
      "0.041066535\n",
      "0.048391357\n",
      "0.042995963\n",
      "0.057948645\n",
      "0.06327108\n",
      "0.04636188\n",
      "0.05577694\n",
      "0.035797395\n",
      "0.051478527\n",
      "0.030253893\n",
      "0.034378335\n",
      "0.038465157\n",
      "0.048403326\n",
      "0.06843679\n",
      "0.05903115\n",
      "0.064792216\n",
      "0.06854533\n",
      "0.039507747\n",
      "0.05789849\n",
      "0.046830896\n",
      "0.033840522\n",
      "0.040746804\n",
      "0.044566926\n",
      "6.860182901844382\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "sess.run(init_g)\n",
    "sess.run(init_l)\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch:  \"+str(i))\n",
    "    #Next Batch of reviews\n",
    "    losses = 0\n",
    "    for j in range(len(X_train)//batchSize):\n",
    "        nextBatch, nextBatchLabels, nextChars = getTrainBatch(j);\n",
    "        #print(j/2)\n",
    "        ll, _,pred,lab = sess.run([loss, optimizer,prediction,labels], {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "        print(ll)\n",
    "        losses += ll\n",
    "\n",
    "    #Write summary to Tensorboard\n",
    "        if (j % 5 == 0):\n",
    "            summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "            writer.add_summary(summary, j)\n",
    "\n",
    "        #Save the network every 10,000 training iterations\n",
    "        if (j % 50 == 0 and j != 0):\n",
    "            save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "            print(\"saved to %s\" % save_path)\n",
    "    print(losses)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(4033.0, 4033.0) (44736.0, 44736.0) (801.0, 801.0) (430.0, 430.0) (0.8353474, 0.83429873) (0.9040168, 0.90365225)\n"
     ]
    }
   ],
   "source": [
    "test_batches = 25\n",
    "fin_pred = np.zeros([test_batches*100, 20, 2])\n",
    "jj = 0\n",
    "for j in range(test_batches):\n",
    "    jj = j * 100\n",
    "    nextBatch, nextBatchLabels, nextChars = getTestBatch(j);\n",
    "    pred, acc, tp, tn, fp, fn, p, r = sess.run([prediction, accuracy, true_positives, true_negatives, false_positives, false_negatives, prec, rec], {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "    print(pred.shape)\n",
    "    fin_pred[jj:jj+100] = pred\n",
    "\n",
    "print(tp,tn,fp,fn,p,r)\n",
    "    #    for i in range(10):\n",
    "\n",
    "#        print(pred[i][:6])\n",
    "#        print(nextBatchLabels[i][:6])\n",
    "#        print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_analysis = {'original_text': [], 'pred_original_text': [], 'body': []}\n",
    "#for i in range(len(y_test)):\n",
    "for i in range((test_batches*100)):\n",
    "    body = word_tokenize(str(raw_data[train_len:].iloc[i]['body']))\n",
    "    lab_index_test = np.where(np.argmax(y_test, axis=2)[i]==1)[0]\n",
    "    lab_index_pred = np.where(np.argmax(fin_pred, axis=2)[i]==1)[0]\n",
    "    original_text = []\n",
    "    pred_original_text = []\n",
    "    for j in lab_index_test:\n",
    "        original_text.append(body[j])\n",
    "    for j in lab_index_pred:\n",
    "        pred_original_text.append(body[j])\n",
    "\n",
    "    prediction_analysis['original_text'].append(original_text)\n",
    "    prediction_analysis['pred_original_text'].append(pred_original_text)\n",
    "    prediction_analysis['body'].append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_analysis_pandas = pd.DataFrame.from_dict(prediction_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tru_pos = 0\n",
    "fals_pos = 0 \n",
    "fals_neg = 0\n",
    "true_pos = []\n",
    "false_pos = []\n",
    "false_neg = []\n",
    "def check_tp(original_text, pred_original_text):\n",
    "    global tru_pos, fals_pos, fals_neg\n",
    "    #print((set(original_text)))\n",
    "    #print((set(pred_original_text)))\n",
    "    og = set(original_text)\n",
    "    pr = set(pred_original_text)\n",
    "    res = og.intersection(pr)\n",
    "    true_pos.append(res)\n",
    "    \n",
    "    false_pos.append(pr - res)\n",
    "    false_neg.append(og - res)\n",
    "    tru_pos += len((set(original_text).intersection(pred_original_text)))\n",
    "    fals_pos += len(pr -res)\n",
    "    fals_neg += len(og - res)\n",
    "    \n",
    "for i in range(2500):\n",
    "    check_tp(prediction_analysis_pandas.iloc[i]['original_text'], prediction_analysis_pandas.iloc[i]['pred_original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4025, 799, 411, 0.8343698175787728, 0.9073489630297565, 0.8693304535637149)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = tru_pos/ (tru_pos + fals_pos)\n",
    "rr = tru_pos/ (tru_pos + fals_neg)\n",
    "tru_pos, fals_pos, fals_neg, pp, rr, (2*pp*rr)/(pp+rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_analysis_pandas['false_positives'] = false_pos\n",
    "prediction_analysis_pandas['true_positives'] = true_pos\n",
    "prediction_analysis_pandas['false_negatives'] = false_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>original_text</th>\n",
       "      <th>pred_original_text</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, call, on, just, dial, .., its, better, the...</td>\n",
       "      <td>[samsung]</td>\n",
       "      <td>[call]</td>\n",
       "      <td>{call}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{samsung}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, want, ambala, bus, stand, context, no, .]</td>\n",
       "      <td>[bus, stand]</td>\n",
       "      <td>[ambala, stand]</td>\n",
       "      <td>{ambala}</td>\n",
       "      <td>{stand}</td>\n",
       "      <td>{bus}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Beauty, parlour, for, women]</td>\n",
       "      <td>[Beauty, parlour]</td>\n",
       "      <td>[Beauty, parlour, women]</td>\n",
       "      <td>{women}</td>\n",
       "      <td>{parlour, Beauty}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Its, not, a, night, club, dear]</td>\n",
       "      <td>[night, club]</td>\n",
       "      <td>[night, club]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{night, club}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[More, Nearby, :, workshop]</td>\n",
       "      <td>[workshop]</td>\n",
       "      <td>[workshop]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{workshop}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Not, send, me, agai]</td>\n",
       "      <td>[agai]</td>\n",
       "      <td>[send, agai]</td>\n",
       "      <td>{send}</td>\n",
       "      <td>{agai}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Car, workshop]</td>\n",
       "      <td>[Car, workshop]</td>\n",
       "      <td>[Car, workshop]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Car, workshop}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Daraganj]</td>\n",
       "      <td>[Daraganj]</td>\n",
       "      <td>[Daraganj]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Daraganj}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Look, for, him]</td>\n",
       "      <td>[for, him]</td>\n",
       "      <td>[Look, him]</td>\n",
       "      <td>{Look}</td>\n",
       "      <td>{him}</td>\n",
       "      <td>{for}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Nearby, sbi, branch]</td>\n",
       "      <td>[sbi, branch]</td>\n",
       "      <td>[sbi, branch]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{sbi, branch}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Naaa]</td>\n",
       "      <td>[Naaa]</td>\n",
       "      <td>[Naaa]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Naaa}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Exchange]</td>\n",
       "      <td>[Exchange]</td>\n",
       "      <td>[Exchange]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Exchange}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Search, Again, Nearby, Nearby, :, Bars]</td>\n",
       "      <td>[Bars]</td>\n",
       "      <td>[Bars]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Bars}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Tomar, Naam, Ki]</td>\n",
       "      <td>[Tomar, Naam]</td>\n",
       "      <td>[Tomar, Naam]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Naam, Tomar}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[CALL, girls]</td>\n",
       "      <td>[girls]</td>\n",
       "      <td>[CALL, girls]</td>\n",
       "      <td>{CALL}</td>\n",
       "      <td>{girls}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Search, Again, Nearby, Nearby, :, CALL, girls]</td>\n",
       "      <td>[CALL, girls]</td>\n",
       "      <td>[CALL, girls]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{girls, CALL}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Tempal]</td>\n",
       "      <td>[Tempal]</td>\n",
       "      <td>[Tempal]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Tempal}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Who, is, Shaheen]</td>\n",
       "      <td>[Shaheen]</td>\n",
       "      <td>[Shaheen]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Shaheen}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Are, you, shaheen, ?, ?]</td>\n",
       "      <td>[shaheen]</td>\n",
       "      <td>[Are, shaheen]</td>\n",
       "      <td>{Are}</td>\n",
       "      <td>{shaheen}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Pizza, uncle]</td>\n",
       "      <td>[Pizza, uncle]</td>\n",
       "      <td>[Pizza, uncle]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{uncle, Pizza}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[YY]</td>\n",
       "      <td>[YY]</td>\n",
       "      <td>[YY]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{YY}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[Mojai, garo, para]</td>\n",
       "      <td>[garo]</td>\n",
       "      <td>[Mojai, garo, para]</td>\n",
       "      <td>{para, Mojai}</td>\n",
       "      <td>{garo}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[for, men]</td>\n",
       "      <td>[men]</td>\n",
       "      <td>[men]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{men}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[Search, Again, Nearby, Nearby, :, Hindi]</td>\n",
       "      <td>[Hindi]</td>\n",
       "      <td>[Hindi]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Hindi}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[Bekri]</td>\n",
       "      <td>[Bekri]</td>\n",
       "      <td>[Bekri]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Bekri}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[Raja, pul, petrol, pumu]</td>\n",
       "      <td>[Raja, pul, petrol]</td>\n",
       "      <td>[Raja, petrol, pumu]</td>\n",
       "      <td>{pumu}</td>\n",
       "      <td>{petrol, Raja}</td>\n",
       "      <td>{pul}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[Search, Again, Nearby, Nearby, :, Sexx]</td>\n",
       "      <td>[Sexx]</td>\n",
       "      <td>[Sexx]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Sexx}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[More, Nearby, :, super, markets]</td>\n",
       "      <td>[super, markets]</td>\n",
       "      <td>[super, markets]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{markets, super}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[Send, you, image]</td>\n",
       "      <td>[you, image]</td>\n",
       "      <td>[Send, image]</td>\n",
       "      <td>{Send}</td>\n",
       "      <td>{image}</td>\n",
       "      <td>{you}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[Hazratganj, lko]</td>\n",
       "      <td>[Hazratganj, lko]</td>\n",
       "      <td>[Hazratganj, lko]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Hazratganj, lko}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>[Sbi, dipojit]</td>\n",
       "      <td>[Sbi, dipojit]</td>\n",
       "      <td>[Sbi, dipojit]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{dipojit, Sbi}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>[Pika, ma, ja]</td>\n",
       "      <td>[Pika]</td>\n",
       "      <td>[Pika, ma, ja]</td>\n",
       "      <td>{ma, ja}</td>\n",
       "      <td>{Pika}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>[Unian, bank, atm]</td>\n",
       "      <td>[Unian, bank, atm]</td>\n",
       "      <td>[Unian, bank, atm]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{bank, Unian, atm}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>[Body, massage, parlour]</td>\n",
       "      <td>[massage, parlour]</td>\n",
       "      <td>[Body, massage, parlour]</td>\n",
       "      <td>{Body}</td>\n",
       "      <td>{massage, parlour}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>[cyber, cafe, near, me]</td>\n",
       "      <td>[cyber, cafe]</td>\n",
       "      <td>[cyber, cafe]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{cafe, cyber}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>[More, Nearby, :, veg, resturant]</td>\n",
       "      <td>[veg, resturant]</td>\n",
       "      <td>[veg, resturant]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{veg, resturant}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>[Ameerpet, andrabank]</td>\n",
       "      <td>[Ameerpet, andrabank]</td>\n",
       "      <td>[Ameerpet, andrabank]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Ameerpet, andrabank}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>[Mail, position]</td>\n",
       "      <td>[Mail, position]</td>\n",
       "      <td>[Mail, position]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{position, Mail}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>[Samsung, s8, how, many, rupes]</td>\n",
       "      <td>[Samsung, rupes]</td>\n",
       "      <td>[Samsung, s8, rupes]</td>\n",
       "      <td>{s8}</td>\n",
       "      <td>{rupes, Samsung}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>[More, Nearby, :, car, spareparts]</td>\n",
       "      <td>[car, spareparts]</td>\n",
       "      <td>[car, spareparts]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{car, spareparts}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>[IndusInd, bank, Atm]</td>\n",
       "      <td>[IndusInd, bank, Atm]</td>\n",
       "      <td>[IndusInd, bank, Atm]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{bank, Atm, IndusInd}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>[M, looking, for, nbad, atm, machine]</td>\n",
       "      <td>[nbad, atm, machine]</td>\n",
       "      <td>[atm]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{atm}</td>\n",
       "      <td>{nbad, machine}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>[Traval, place]</td>\n",
       "      <td>[Traval, place]</td>\n",
       "      <td>[Traval, place]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Traval, place}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>[Please, show, near, by, machine, workshop]</td>\n",
       "      <td>[machine, workshop]</td>\n",
       "      <td>[Please, show]</td>\n",
       "      <td>{Please, show}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{machine, workshop}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>[Nearby, any, hotel, in, Mangalore, rent]</td>\n",
       "      <td>[hotel]</td>\n",
       "      <td>[hotel, rent]</td>\n",
       "      <td>{rent}</td>\n",
       "      <td>{hotel}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>[Where, movie, are, play]</td>\n",
       "      <td>[movie]</td>\n",
       "      <td>[movie]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{movie}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>[Hey, can, you, find, nearby, hotel]</td>\n",
       "      <td>[hotel]</td>\n",
       "      <td>[hotel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{hotel}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>[Can, you, find, restaurant, near, by]</td>\n",
       "      <td>[restaurant]</td>\n",
       "      <td>[restaurant]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{restaurant}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>[Nearby, Issue, Details, Issue, Details, :, Fo...</td>\n",
       "      <td>[Food, food]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{food, Food}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>[Hey, can, you, find, a, entirtement]</td>\n",
       "      <td>[entirtement]</td>\n",
       "      <td>[entirtement]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{entirtement}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>[Can, you, find, for, me, bus]</td>\n",
       "      <td>[bus]</td>\n",
       "      <td>[bus]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{bus}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>[More, Nearby, :, sex, workers]</td>\n",
       "      <td>[sex, workers]</td>\n",
       "      <td>[sex, workers]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{workers, sex}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>[Ayb, yq]</td>\n",
       "      <td>[Ayb, yq]</td>\n",
       "      <td>[Ayb, yq]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Ayb, yq}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>[Not, tolk, to, you]</td>\n",
       "      <td>[tolk]</td>\n",
       "      <td>[tolk, to, you]</td>\n",
       "      <td>{you, to}</td>\n",
       "      <td>{tolk}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>[Etamall, kaala, film, runing]</td>\n",
       "      <td>[Etamall, film]</td>\n",
       "      <td>[Etamall, kaala, film, runing]</td>\n",
       "      <td>{runing, kaala}</td>\n",
       "      <td>{Etamall, film}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>[Fitness, center]</td>\n",
       "      <td>[Fitness]</td>\n",
       "      <td>[Fitness, center]</td>\n",
       "      <td>{center}</td>\n",
       "      <td>{Fitness}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>[i, want, a, canon, shop]</td>\n",
       "      <td>[canon, shop]</td>\n",
       "      <td>[canon, shop]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{shop, canon}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>[i, want, a, near, me, ayurvadic, spa]</td>\n",
       "      <td>[ayurvadic, spa]</td>\n",
       "      <td>[spa]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{spa}</td>\n",
       "      <td>{ayurvadic}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>[More, Nearby, :, phone, shop]</td>\n",
       "      <td>[phone, shop]</td>\n",
       "      <td>[phone, shop]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{shop, phone}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>[Salon, for, women]</td>\n",
       "      <td>[Salon]</td>\n",
       "      <td>[Salon, for, women]</td>\n",
       "      <td>{for, women}</td>\n",
       "      <td>{Salon}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     [i, call, on, just, dial, .., its, better, the...   \n",
       "1         [i, want, ambala, bus, stand, context, no, .]   \n",
       "2                         [Beauty, parlour, for, women]   \n",
       "3                      [Its, not, a, night, club, dear]   \n",
       "4                           [More, Nearby, :, workshop]   \n",
       "5                                 [Not, send, me, agai]   \n",
       "6                                       [Car, workshop]   \n",
       "7                                            [Daraganj]   \n",
       "8                                      [Look, for, him]   \n",
       "9                                 [Nearby, sbi, branch]   \n",
       "10                                               [Naaa]   \n",
       "11                                           [Exchange]   \n",
       "12             [Search, Again, Nearby, Nearby, :, Bars]   \n",
       "13                                    [Tomar, Naam, Ki]   \n",
       "14                                        [CALL, girls]   \n",
       "15      [Search, Again, Nearby, Nearby, :, CALL, girls]   \n",
       "16                                             [Tempal]   \n",
       "17                                   [Who, is, Shaheen]   \n",
       "18                            [Are, you, shaheen, ?, ?]   \n",
       "19                                       [Pizza, uncle]   \n",
       "20                                                 [YY]   \n",
       "21                                  [Mojai, garo, para]   \n",
       "22                                           [for, men]   \n",
       "23            [Search, Again, Nearby, Nearby, :, Hindi]   \n",
       "24                                              [Bekri]   \n",
       "25                            [Raja, pul, petrol, pumu]   \n",
       "26             [Search, Again, Nearby, Nearby, :, Sexx]   \n",
       "27                    [More, Nearby, :, super, markets]   \n",
       "28                                   [Send, you, image]   \n",
       "29                                    [Hazratganj, lko]   \n",
       "...                                                 ...   \n",
       "2470                                     [Sbi, dipojit]   \n",
       "2471                                     [Pika, ma, ja]   \n",
       "2472                                 [Unian, bank, atm]   \n",
       "2473                           [Body, massage, parlour]   \n",
       "2474                            [cyber, cafe, near, me]   \n",
       "2475                  [More, Nearby, :, veg, resturant]   \n",
       "2476                              [Ameerpet, andrabank]   \n",
       "2477                                   [Mail, position]   \n",
       "2478                    [Samsung, s8, how, many, rupes]   \n",
       "2479                 [More, Nearby, :, car, spareparts]   \n",
       "2480                              [IndusInd, bank, Atm]   \n",
       "2481              [M, looking, for, nbad, atm, machine]   \n",
       "2482                                    [Traval, place]   \n",
       "2483        [Please, show, near, by, machine, workshop]   \n",
       "2484          [Nearby, any, hotel, in, Mangalore, rent]   \n",
       "2485                          [Where, movie, are, play]   \n",
       "2486               [Hey, can, you, find, nearby, hotel]   \n",
       "2487             [Can, you, find, restaurant, near, by]   \n",
       "2488  [Nearby, Issue, Details, Issue, Details, :, Fo...   \n",
       "2489              [Hey, can, you, find, a, entirtement]   \n",
       "2490                     [Can, you, find, for, me, bus]   \n",
       "2491                    [More, Nearby, :, sex, workers]   \n",
       "2492                                          [Ayb, yq]   \n",
       "2493                               [Not, tolk, to, you]   \n",
       "2494                     [Etamall, kaala, film, runing]   \n",
       "2495                                  [Fitness, center]   \n",
       "2496                          [i, want, a, canon, shop]   \n",
       "2497             [i, want, a, near, me, ayurvadic, spa]   \n",
       "2498                     [More, Nearby, :, phone, shop]   \n",
       "2499                                [Salon, for, women]   \n",
       "\n",
       "              original_text              pred_original_text  false_positives  \\\n",
       "0                 [samsung]                          [call]           {call}   \n",
       "1              [bus, stand]                 [ambala, stand]         {ambala}   \n",
       "2         [Beauty, parlour]        [Beauty, parlour, women]          {women}   \n",
       "3             [night, club]                   [night, club]               {}   \n",
       "4                [workshop]                      [workshop]               {}   \n",
       "5                    [agai]                    [send, agai]           {send}   \n",
       "6           [Car, workshop]                 [Car, workshop]               {}   \n",
       "7                [Daraganj]                      [Daraganj]               {}   \n",
       "8                [for, him]                     [Look, him]           {Look}   \n",
       "9             [sbi, branch]                   [sbi, branch]               {}   \n",
       "10                   [Naaa]                          [Naaa]               {}   \n",
       "11               [Exchange]                      [Exchange]               {}   \n",
       "12                   [Bars]                          [Bars]               {}   \n",
       "13            [Tomar, Naam]                   [Tomar, Naam]               {}   \n",
       "14                  [girls]                   [CALL, girls]           {CALL}   \n",
       "15            [CALL, girls]                   [CALL, girls]               {}   \n",
       "16                 [Tempal]                        [Tempal]               {}   \n",
       "17                [Shaheen]                       [Shaheen]               {}   \n",
       "18                [shaheen]                  [Are, shaheen]            {Are}   \n",
       "19           [Pizza, uncle]                  [Pizza, uncle]               {}   \n",
       "20                     [YY]                            [YY]               {}   \n",
       "21                   [garo]             [Mojai, garo, para]    {para, Mojai}   \n",
       "22                    [men]                           [men]               {}   \n",
       "23                  [Hindi]                         [Hindi]               {}   \n",
       "24                  [Bekri]                         [Bekri]               {}   \n",
       "25      [Raja, pul, petrol]            [Raja, petrol, pumu]           {pumu}   \n",
       "26                   [Sexx]                          [Sexx]               {}   \n",
       "27         [super, markets]                [super, markets]               {}   \n",
       "28             [you, image]                   [Send, image]           {Send}   \n",
       "29        [Hazratganj, lko]               [Hazratganj, lko]               {}   \n",
       "...                     ...                             ...              ...   \n",
       "2470         [Sbi, dipojit]                  [Sbi, dipojit]               {}   \n",
       "2471                 [Pika]                  [Pika, ma, ja]         {ma, ja}   \n",
       "2472     [Unian, bank, atm]              [Unian, bank, atm]               {}   \n",
       "2473     [massage, parlour]        [Body, massage, parlour]           {Body}   \n",
       "2474          [cyber, cafe]                   [cyber, cafe]               {}   \n",
       "2475       [veg, resturant]                [veg, resturant]               {}   \n",
       "2476  [Ameerpet, andrabank]           [Ameerpet, andrabank]               {}   \n",
       "2477       [Mail, position]                [Mail, position]               {}   \n",
       "2478       [Samsung, rupes]            [Samsung, s8, rupes]             {s8}   \n",
       "2479      [car, spareparts]               [car, spareparts]               {}   \n",
       "2480  [IndusInd, bank, Atm]           [IndusInd, bank, Atm]               {}   \n",
       "2481   [nbad, atm, machine]                           [atm]               {}   \n",
       "2482        [Traval, place]                 [Traval, place]               {}   \n",
       "2483    [machine, workshop]                  [Please, show]   {Please, show}   \n",
       "2484                [hotel]                   [hotel, rent]           {rent}   \n",
       "2485                [movie]                         [movie]               {}   \n",
       "2486                [hotel]                         [hotel]               {}   \n",
       "2487           [restaurant]                    [restaurant]               {}   \n",
       "2488           [Food, food]                              []               {}   \n",
       "2489          [entirtement]                   [entirtement]               {}   \n",
       "2490                  [bus]                           [bus]               {}   \n",
       "2491         [sex, workers]                  [sex, workers]               {}   \n",
       "2492              [Ayb, yq]                       [Ayb, yq]               {}   \n",
       "2493                 [tolk]                 [tolk, to, you]        {you, to}   \n",
       "2494        [Etamall, film]  [Etamall, kaala, film, runing]  {runing, kaala}   \n",
       "2495              [Fitness]               [Fitness, center]         {center}   \n",
       "2496          [canon, shop]                   [canon, shop]               {}   \n",
       "2497       [ayurvadic, spa]                           [spa]               {}   \n",
       "2498          [phone, shop]                   [phone, shop]               {}   \n",
       "2499                [Salon]             [Salon, for, women]     {for, women}   \n",
       "\n",
       "             true_positives      false_negatives  \n",
       "0                        {}            {samsung}  \n",
       "1                   {stand}                {bus}  \n",
       "2         {parlour, Beauty}                   {}  \n",
       "3             {night, club}                   {}  \n",
       "4                {workshop}                   {}  \n",
       "5                    {agai}                   {}  \n",
       "6           {Car, workshop}                   {}  \n",
       "7                {Daraganj}                   {}  \n",
       "8                     {him}                {for}  \n",
       "9             {sbi, branch}                   {}  \n",
       "10                   {Naaa}                   {}  \n",
       "11               {Exchange}                   {}  \n",
       "12                   {Bars}                   {}  \n",
       "13            {Naam, Tomar}                   {}  \n",
       "14                  {girls}                   {}  \n",
       "15            {girls, CALL}                   {}  \n",
       "16                 {Tempal}                   {}  \n",
       "17                {Shaheen}                   {}  \n",
       "18                {shaheen}                   {}  \n",
       "19           {uncle, Pizza}                   {}  \n",
       "20                     {YY}                   {}  \n",
       "21                   {garo}                   {}  \n",
       "22                    {men}                   {}  \n",
       "23                  {Hindi}                   {}  \n",
       "24                  {Bekri}                   {}  \n",
       "25           {petrol, Raja}                {pul}  \n",
       "26                   {Sexx}                   {}  \n",
       "27         {markets, super}                   {}  \n",
       "28                  {image}                {you}  \n",
       "29        {Hazratganj, lko}                   {}  \n",
       "...                     ...                  ...  \n",
       "2470         {dipojit, Sbi}                   {}  \n",
       "2471                 {Pika}                   {}  \n",
       "2472     {bank, Unian, atm}                   {}  \n",
       "2473     {massage, parlour}                   {}  \n",
       "2474          {cafe, cyber}                   {}  \n",
       "2475       {veg, resturant}                   {}  \n",
       "2476  {Ameerpet, andrabank}                   {}  \n",
       "2477       {position, Mail}                   {}  \n",
       "2478       {rupes, Samsung}                   {}  \n",
       "2479      {car, spareparts}                   {}  \n",
       "2480  {bank, Atm, IndusInd}                   {}  \n",
       "2481                  {atm}      {nbad, machine}  \n",
       "2482        {Traval, place}                   {}  \n",
       "2483                     {}  {machine, workshop}  \n",
       "2484                {hotel}                   {}  \n",
       "2485                {movie}                   {}  \n",
       "2486                {hotel}                   {}  \n",
       "2487           {restaurant}                   {}  \n",
       "2488                     {}         {food, Food}  \n",
       "2489          {entirtement}                   {}  \n",
       "2490                  {bus}                   {}  \n",
       "2491         {workers, sex}                   {}  \n",
       "2492              {Ayb, yq}                   {}  \n",
       "2493                 {tolk}                   {}  \n",
       "2494        {Etamall, film}                   {}  \n",
       "2495              {Fitness}                   {}  \n",
       "2496          {shop, canon}                   {}  \n",
       "2497                  {spa}          {ayurvadic}  \n",
       "2498          {shop, phone}                   {}  \n",
       "2499                {Salon}                   {}  \n",
       "\n",
       "[2500 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_analysis_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
